#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Metadataæ›´æ–°è„šæœ¬

æœ¬è„šæœ¬ç”¨äºæ›´æ–°timelineç›®å½•ä¸­HTMLæ–‡ä»¶çš„å…ƒæ•°æ®ä¿¡æ¯ã€‚
é€šå¸¸ç”±file.pyè‡ªåŠ¨è°ƒç”¨ï¼Œä¹Ÿå¯ä»¥æ‰‹åŠ¨è¿è¡Œè¿›è¡Œå¢é‡æˆ–å…¨é‡æ›´æ–°ã€‚

## ç”Ÿæˆè§„åˆ™å’Œè¦æ±‚

### æ ‡ç­¾ç”Ÿæˆè§„åˆ™
1. **æ•°é‡é™åˆ¶**: æ¯ç¯‡æ–‡ç« ä¸¥æ ¼é™åˆ¶ä¸º3ä¸ªæ ‡ç­¾
2. **åˆ†å±‚é€»è¾‘**: æŒ‰ç…§ä»å¤§åˆ°å°çš„åˆ†å±‚é€»è¾‘æ’åˆ—ï¼ˆå¤§åˆ†ç±» â†’ ç»†åˆ†ç±» â†’ å…·ä½“æ ‡ç­¾ï¼‰
3. **æ ‡ç­¾ç®€æ´**: æ¯ä¸ªæ ‡ç­¾1-3ä¸ªå­—ï¼Œç®€æ´æ˜äº†
4. **å‡†ç¡®åæ˜ **: æ ‡ç­¾è¦å‡†ç¡®åæ˜ æ–‡ç« çš„æ ¸å¿ƒä¸»é¢˜å’Œå†…å®¹

### æ ‡é¢˜ç”Ÿæˆè§„åˆ™
1. **ä½¿ç”¨æ–‡ä»¶å**: æ ‡é¢˜ç›´æ¥ä½¿ç”¨HTMLæ–‡ä»¶åï¼ˆå»æ‰.htmlåç¼€ï¼‰
2. **æ–‡ä»¶åå³æ ‡é¢˜**: æ–‡ä»¶å¤åˆ¶åˆ°timelineç›®å½•æ—¶åº”è¯¥å·²ç»ç”¨HTMLçš„<title>æ ‡ç­¾é‡å‘½å
3. **ä¿æŒåŸæ ·**: ä¸å¯¹æ–‡ä»¶åè¿›è¡Œé¢å¤–å¤„ç†ï¼Œä¿æŒé‡å‘½ååçš„æ ‡é¢˜

### æ—¥æœŸç”Ÿæˆè§„åˆ™
1. **æ–‡ä»¶åˆ›å»ºæ—¶é—´**: ä½¿ç”¨æ–‡ä»¶çš„å®é™…åˆ›å»ºæ—¶é—´ä½œä¸ºæ—¥æœŸ
2. **æ ¼å¼æ ‡å‡†**: æ—¥æœŸæ ¼å¼ä¸ºYYYY-MM-DD
3. **å¤‡é€‰æ–¹æ¡ˆ**: å¦‚æœæ— æ³•è·å–åˆ›å»ºæ—¶é—´ï¼Œä½¿ç”¨æ–‡ä»¶ä¿®æ”¹æ—¶é—´

### æ›´æ–°æ¨¡å¼
1. **é»˜è®¤å¢é‡æ›´æ–°**: é»˜è®¤åªå¤„ç†æ–°å¢çš„HTMLæ–‡ä»¶ï¼ˆdiffæ¨¡å¼ï¼‰
2. **å…¨é‡æ›´æ–°**: ä½¿ç”¨--allå‚æ•°æ—¶æ›´æ–°æ‰€æœ‰æ–‡ä»¶
3. **é¢„è§ˆæ¨¡å¼**: ä½¿ç”¨--dry-runå‚æ•°å¯é¢„è§ˆæ›´æ”¹è€Œä¸å®é™…ä¿å­˜

### æ ¼å¼è¦æ±‚
1. **Tagsä¸€è¡Œæ˜¾ç¤º**: tagsæ•°ç»„åœ¨JSONä¸­æ˜¾ç¤ºä¸ºä¸€è¡Œï¼Œå¦‚ "tags": ["AI", "æŠ€æœ¯", "åº”ç”¨"]
2. **æ—¥æœŸå€’åºæ’åˆ—**: æ‰€æœ‰æ¡ç›®æŒ‰dateå­—æ®µå€’åºæ’åˆ—ï¼Œæœ€æ–°æ–‡ç« åœ¨å‰
3. **åŒæ—¥æœŸåæ¥è€…å±…ä¸Š**: å¦‚æœæ—¥æœŸç›¸åŒï¼Œæ–°æ·»åŠ çš„æ–‡ä»¶æ’åœ¨å‰é¢ï¼ˆåæ¥è€…å±…ä¸ŠåŸåˆ™ï¼‰
4. **JSONæ ¼å¼**: ä¿æŒJSONæ ¼å¼çš„å¯è¯»æ€§å’Œä¸€è‡´æ€§
5. **ç¼–ç æ ¼å¼**: ä½¿ç”¨UTF-8ç¼–ç ï¼Œensure_ascii=Falseä¿æŒä¸­æ–‡æ˜¾ç¤º

### ä½¿ç”¨æ–¹æ³•
æ³¨æ„ï¼šè„šæœ¬éœ€è¦åœ¨cacheç›®å½•ä¸‹è¿è¡Œ
- cd cache && python3 update.py              # å¢é‡æ›´æ–°(åªå¤„ç†æ–°æ–‡ä»¶)
- cd cache && python3 update.py --all        # å…¨é‡æ›´æ–°æ‰€æœ‰æ–‡ä»¶
- cd cache && python3 update.py --dry-run    # é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…ä¿å­˜
- cd cache && python3 update.py --all --dry-run  # å…¨é‡é¢„è§ˆæ¨¡å¼

### å·¥ä½œæµç¨‹
1. ä½¿ç”¨file.pyå¤„ç†ä¸‹è½½ç›®å½•ä¸­çš„HTMLæ–‡ä»¶ï¼ˆæå–æ ‡é¢˜å¹¶é‡å‘½åï¼Œè‡ªåŠ¨è°ƒç”¨update.pyï¼‰
2. è„šæœ¬æ£€æµ‹docs/timeline/ç›®å½•ä¸‹çš„æ‰€æœ‰HTMLæ–‡ä»¶ï¼ˆä»cacheç›®å½•è¿è¡Œæ—¶ä½¿ç”¨../docs/timeline/ï¼‰
3. å¯¹æ¯”ç°æœ‰metadata.jsonï¼Œæ‰¾å‡ºæ–°å¢æ–‡ä»¶ï¼ˆå¢é‡æ¨¡å¼ï¼‰æˆ–å¤„ç†æ‰€æœ‰æ–‡ä»¶ï¼ˆå…¨é‡æ¨¡å¼ï¼‰
4. ä¸ºæ¯ä¸ªæ–‡ä»¶æå–æ ‡é¢˜ï¼ˆæ–‡ä»¶åï¼‰å’Œæ—¥æœŸï¼ˆåˆ›å»ºæ—¶é—´ï¼‰
5. æ ‡ç­¾éœ€è¦é€šè¿‡AIåŠ©æ‰‹ç”Ÿæˆ
6. æ™ºèƒ½æ’å…¥æ–°æ–‡ä»¶åˆ°æ­£ç¡®ä½ç½®ï¼Œä¿æŒæ—¥æœŸå€’åºå’Œ"åæ¥è€…å±…ä¸Š"åŸåˆ™
7. ä¿å­˜ä¸ºæ ¼å¼åŒ–çš„JSONæ–‡ä»¶

### æ³¨æ„äº‹é¡¹
- æ–‡ä»¶åº”è¯¥å…ˆé€šè¿‡file.pyå¤„ç†ï¼Œç¡®ä¿æ–‡ä»¶åå°±æ˜¯æ–‡ç« æ ‡é¢˜
- æ ‡ç­¾éœ€è¦é€šè¿‡AIåŠ©æ‰‹ç”Ÿæˆï¼Œè„šæœ¬åªæä¾›å ä½ç¬¦
- æ’åºéµå¾ª"åæ¥è€…å±…ä¸Š"åŸåˆ™ï¼šåŒæ—¥æœŸæ–‡ä»¶ä¸­ï¼Œæ–°æ·»åŠ çš„æ–‡ä»¶ä¼šè‡ªåŠ¨æ’åœ¨å‰é¢
- åªå¯¹æ–°æ–‡ä»¶è¿›è¡Œæ’å…¥æ’åºï¼Œä¸ä¼šé‡æ–°æ’åºæ•´ä¸ªæ–‡ä»¶
- ä¿æŒmetadata.jsonæ–‡ä»¶çš„å¤‡ä»½ï¼Œé¿å…æ„å¤–ä¸¢å¤±æ•°æ®
"""

import json
import os
import argparse
from datetime import datetime
from pathlib import Path



def get_file_creation_date(file_path):
    """è·å–æ–‡ä»¶çš„åˆ›å»ºæ—¶é—´"""
    try:
        stat = os.stat(file_path)
        # å°è¯•è·å–åˆ›å»ºæ—¶é—´ï¼ˆmacOSæ”¯æŒst_birthtimeï¼‰
        if hasattr(stat, 'st_birthtime'):
            timestamp = stat.st_birthtime
        else:
            # ä½¿ç”¨ä¿®æ”¹æ—¶é—´ä½œä¸ºå¤‡é€‰
            timestamp = stat.st_mtime
        return datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')
    except:
        return datetime.now().strftime('%Y-%m-%d')

def extract_title_from_filename(file_path):
    """ä»æ–‡ä»¶åæå–æ ‡é¢˜

    æ³¨æ„ï¼šæ–‡ä»¶åº”è¯¥å·²ç»é€šè¿‡file.pyå¤„ç†ï¼Œ
    æ–‡ä»¶åå°±æ˜¯ä»HTML <title>æ ‡ç­¾æå–çš„æ ‡é¢˜
    """
    filename = os.path.basename(file_path)
    return filename.replace('.html', '').strip()



def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç®€å•æ›´æ–°metadata.jsonæ–‡ä»¶')
    parser.add_argument('--all', action='store_true', help='å…¨é‡æ›´æ–°æ‰€æœ‰æ–‡ä»¶ï¼ˆé»˜è®¤ä¸ºå¢é‡æ›´æ–°diffï¼‰')
    parser.add_argument('--dry-run', action='store_true', help='é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…ä¿å­˜æ–‡ä»¶')
    args = parser.parse_args()
    
    mode = "å…¨é‡æ›´æ–°" if args.all else "å¢é‡æ›´æ–°(diff)"
    print(f"ğŸš€ å¼€å§‹{mode}metadata.jsonæ–‡ä»¶...")

    # è¯»å–ç°æœ‰çš„metadata.json
    metadata_path = 'metadata.json'
    try:
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        print(f"ğŸ“– å·²åŠ è½½ç°æœ‰metadataï¼ŒåŒ…å« {len(metadata)} æ¡è®°å½•")
    except FileNotFoundError:
        print("âŒ metadata.jsonæ–‡ä»¶ä¸å­˜åœ¨")
        return
    except Exception as e:
        print(f"âŒ è¯»å–metadata.jsonå¤±è´¥: {e}")
        return

    # è·å–æ‰€æœ‰HTMLæ–‡ä»¶
    timeline_dir = Path('../docs/timeline')
    html_files = list(timeline_dir.glob('*.html'))
    print(f"ğŸ“ æ‰¾åˆ° {len(html_files)} ä¸ªHTMLæ–‡ä»¶")

    # ç¡®å®šéœ€è¦å¤„ç†çš„æ–‡ä»¶
    if args.all:
        files_to_process = html_files
        print(f"ğŸ”„ å…¨é‡æ›´æ–°æ¨¡å¼ï¼šå°†å¤„ç†æ‰€æœ‰ {len(files_to_process)} ä¸ªæ–‡ä»¶")
    else:
        files_to_process = []
        for html_file in html_files:
            # å°†è·¯å¾„æ ‡å‡†åŒ–ä¸ºç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
            file_key = str(html_file).replace('\\', '/').replace('../', '')
            if file_key not in metadata:
                files_to_process.append(html_file)
        print(f"ğŸ†• å¢é‡æ›´æ–°æ¨¡å¼ï¼šå‘ç° {len(files_to_process)} ä¸ªæ–°æ–‡ä»¶éœ€è¦æ·»åŠ ")
    
    if not files_to_process:
        print("âœ… æ²¡æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶")
        return
    
    # å¤„ç†æ–‡ä»¶
    updated_count = 0
    files_to_process_paths = []  # è®°å½•æ–°å¤„ç†çš„æ–‡ä»¶è·¯å¾„
    for html_file in files_to_process:
        # å°†è·¯å¾„æ ‡å‡†åŒ–ä¸ºç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
        file_key = str(html_file).replace('\\', '/').replace('../', '')
        print(f"\nğŸ“ å¤„ç†æ–‡ä»¶: {file_key}")

        # æå–æ ‡é¢˜ï¼ˆä½¿ç”¨æ–‡ä»¶åï¼‰
        title = extract_title_from_filename(html_file)
        print(f"   æ ‡é¢˜: {title}")

        # è·å–æ—¥æœŸï¼ˆæ–‡ä»¶åˆ›å»ºæ—¶é—´ï¼‰
        date = get_file_creation_date(html_file)
        print(f"   æ—¥æœŸ: {date}")

        # æ ‡ç­¾éœ€è¦AIåŠ©æ‰‹ç”Ÿæˆ
        print(f"   æ ‡ç­¾: éœ€è¦AIåŠ©æ‰‹ç”Ÿæˆ")

        # æ·»åŠ æˆ–æ›´æ–°metadataï¼ˆæ ‡ç­¾æš‚æ—¶ä¸ºå ä½ç¬¦ï¼‰
        if args.all or file_key not in metadata:
            metadata[file_key] = {
                "title": title,
                "date": date,
                "tags": ["å¾…ç”Ÿæˆ", "å¾…ç”Ÿæˆ", "å¾…ç”Ÿæˆ"]  # å ä½ç¬¦ï¼Œéœ€è¦AIç”Ÿæˆ
            }
            files_to_process_paths.append(file_key)  # è®°å½•æ–°å¤„ç†çš„æ–‡ä»¶
            updated_count += 1
    
    # åªå¯¹æ–°æ–‡ä»¶è¿›è¡Œæ™ºèƒ½æ’å…¥ï¼Œä¸é‡æ–°æ’åºæ•´ä¸ªæ–‡ä»¶
    if updated_count > 0:
        print(f"\nğŸ“… å°† {updated_count} ä¸ªæ–°æ–‡ä»¶æ’å…¥åˆ°æ­£ç¡®ä½ç½®...")

        # è·å–æ‰€æœ‰æ¡ç›®å¹¶æŒ‰æ—¥æœŸåˆ†ç»„
        all_items = list(metadata.items())

        # åˆ†ç¦»æ–°æ–‡ä»¶å’Œå·²å­˜åœ¨æ–‡ä»¶
        new_files = [(k, v) for k, v in all_items if k in files_to_process_paths]
        existing_files = [(k, v) for k, v in all_items if k not in files_to_process_paths]

        # å¯¹æ–°æ–‡ä»¶æŒ‰æ—¥æœŸæ’åºï¼ˆåŒæ—¥æœŸæŒ‰æ–‡ä»¶åæ’åºä¿è¯ä¸€è‡´æ€§ï¼‰
        new_files.sort(key=lambda x: (x[1]['date'], x[0]), reverse=True)

        # é‡æ–°æ„å»ºmetadataï¼šåˆå¹¶æ–°æ–‡ä»¶å’Œå·²å­˜åœ¨æ–‡ä»¶ï¼Œä¿æŒæ—¥æœŸå€’åº
        result = []
        i, j = 0, 0

        while i < len(existing_files) or j < len(new_files):
            if j >= len(new_files):
                # æ–°æ–‡ä»¶å·²å¤„ç†å®Œï¼Œæ·»åŠ å‰©ä½™å·²å­˜åœ¨æ–‡ä»¶
                result.extend(existing_files[i:])
                break
            elif i >= len(existing_files):
                # å·²å­˜åœ¨æ–‡ä»¶å·²å¤„ç†å®Œï¼Œæ·»åŠ å‰©ä½™æ–°æ–‡ä»¶
                result.extend(new_files[j:])
                break
            else:
                existing_date = existing_files[i][1]['date']
                new_date = new_files[j][1]['date']

                # æ–°æ–‡ä»¶ä¼˜å…ˆï¼šæ—¥æœŸæ›´æ–°æˆ–åŒæ—¥æœŸæ—¶æ–°æ–‡ä»¶åœ¨å‰
                if new_date > existing_date:
                    result.append(new_files[j])
                    j += 1
                elif new_date == existing_date:
                    # åŒæ—¥æœŸæ—¶ï¼Œæ–°æ–‡ä»¶æ’åœ¨å‰é¢
                    result.append(new_files[j])
                    j += 1
                else:
                    result.append(existing_files[i])
                    i += 1

        # é‡å»ºmetadataå­—å…¸
        metadata = dict(result)

    # ä¿å­˜æ›´æ–°åçš„metadata
    if not args.dry_run:
        try:
            # è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œè®©tagsæ•°ç»„åœ¨ä¸€è¡Œæ˜¾ç¤º
            class CompactJSONEncoder(json.JSONEncoder):
                def encode(self, obj):
                    if isinstance(obj, dict):
                        items = []
                        for key, value in obj.items():
                            if isinstance(value, dict):
                                # å¤„ç†æ¯ä¸ªæ–‡ç« æ¡ç›®
                                sub_items = []
                                for sub_key, sub_value in value.items():
                                    if sub_key == 'tags' and isinstance(sub_value, list):
                                        # tagsæ•°ç»„æ”¾åœ¨ä¸€è¡Œ
                                        tag_str = json.dumps(sub_value, ensure_ascii=False)
                                        sub_items.append(f'    "{sub_key}": {tag_str}')
                                    else:
                                        sub_items.append(f'    "{sub_key}": {json.dumps(sub_value, ensure_ascii=False)}')
                                value_str = "{\n" + ",\n".join(sub_items) + "\n  }"
                                items.append(f'  "{key}": {value_str}')
                            else:
                                items.append(f'  "{key}": {json.dumps(value, ensure_ascii=False)}')
                        return "{\n" + ",\n".join(items) + "\n}"
                    return super().encode(obj)

            with open(metadata_path, 'w', encoding='utf-8') as f:
                f.write(CompactJSONEncoder().encode(metadata))

            print(f"\nâœ… metadata.jsonæ›´æ–°å®Œæˆï¼Œç°åœ¨åŒ…å« {len(metadata)} æ¡è®°å½•")
            print(f"ğŸ†• {'æ›´æ–°' if args.all else 'æ–°å¢'}äº† {updated_count} æ¡è®°å½•")
            print("ğŸ¤– è¯·ä½¿ç”¨AIåŠ©æ‰‹ä¸ºæ–°æ–‡ç« ç”Ÿæˆæ ‡ç­¾ï¼ˆæ›¿æ¢'å¾…ç”Ÿæˆ'å ä½ç¬¦ï¼‰")
        except Exception as e:
            print(f"âŒ ä¿å­˜metadata.jsonå¤±è´¥: {e}")
    else:
        print(f"\nğŸ” é¢„è§ˆæ¨¡å¼ï¼šå°†{'æ›´æ–°' if args.all else 'æ–°å¢'} {updated_count} æ¡è®°å½•")

if __name__ == "__main__":
    main()
